<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>ü§ñ The Promise and Peril of AI in English Language Education: What Educators Need to Know | Phuong Anh's Corner</title>
<meta name=keywords content><meta name=description content="Since ChatGPT burst onto the scene in November 2022 [18], educators worldwide have been grappling with a fundamental question: What are Large Language Models (LLMs) and How do we integrate Large Language Models (LLMs) into English language teaching?
In the recent Symposium  on  Using  AI  in  Foreign  Language  Teaching hosted by FTU&rsquo;s Faculty of ESP, I wrote a short paper that tries to go against of this hype and provide a balanced view of the challenges that AI presents in language education. This post summarizes the key points from that paper, which is available in full here."><meta name=author content><link rel=canonical href=https://dophganhh.github.io/posts/ai-challenges-in-education/><link crossorigin=anonymous href=/assets/css/stylesheet.d6fcd20a4fb86efa4dfac8ec95da60244cc8871042183da1ef28e3a762ad79c8.css integrity="sha256-1vzSCk+4bvpN+sjsldpgJEzIhxBCGD2h7yjjp2Ktecg=" rel="preload stylesheet" as=style><link rel=icon href=https://dophganhh.github.io/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://dophganhh.github.io/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://dophganhh.github.io/favicon-32x32.png><link rel=apple-touch-icon href=https://dophganhh.github.io/apple-touch-icon.png><link rel=mask-icon href=https://dophganhh.github.io/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://dophganhh.github.io/posts/ai-challenges-in-education/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><meta property="og:url" content="https://dophganhh.github.io/posts/ai-challenges-in-education/"><meta property="og:site_name" content="Phuong Anh's Corner"><meta property="og:title" content="ü§ñ The Promise and Peril of AI in English Language Education: What Educators Need to Know"><meta property="og:description" content="Since ChatGPT burst onto the scene in November 2022 [18], educators worldwide have been grappling with a fundamental question: What are Large Language Models (LLMs) and How do we integrate Large Language Models (LLMs) into English language teaching?
In the recent Symposium on Using AI in Foreign Language Teaching hosted by FTU‚Äôs Faculty of ESP, I wrote a short paper that tries to go against of this hype and provide a balanced view of the challenges that AI presents in language education. This post summarizes the key points from that paper, which is available in full here."><meta property="og:locale" content="en-us"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2024-06-20T17:01:23+00:00"><meta property="article:modified_time" content="2024-06-20T17:01:23+00:00"><meta name=twitter:card content="summary"><meta name=twitter:title content="ü§ñ The Promise and Peril of AI in English Language Education: What Educators Need to Know"><meta name=twitter:description content="Since ChatGPT burst onto the scene in November 2022 [18], educators worldwide have been grappling with a fundamental question: What are Large Language Models (LLMs) and How do we integrate Large Language Models (LLMs) into English language teaching?
In the recent Symposium  on  Using  AI  in  Foreign  Language  Teaching hosted by FTU&rsquo;s Faculty of ESP, I wrote a short paper that tries to go against of this hype and provide a balanced view of the challenges that AI presents in language education. This post summarizes the key points from that paper, which is available in full here."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://dophganhh.github.io/posts/"},{"@type":"ListItem","position":2,"name":"ü§ñ The Promise and Peril of AI in English Language Education: What Educators Need to Know","item":"https://dophganhh.github.io/posts/ai-challenges-in-education/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"ü§ñ The Promise and Peril of AI in English Language Education: What Educators Need to Know","name":"ü§ñ The Promise and Peril of AI in English Language Education: What Educators Need to Know","description":"Since ChatGPT burst onto the scene in November 2022 [18], educators worldwide have been grappling with a fundamental question: What are Large Language Models (LLMs) and How do we integrate Large Language Models (LLMs) into English language teaching?\nIn the recent Symposium on Using AI in Foreign Language Teaching hosted by FTU\u0026rsquo;s Faculty of ESP, I wrote a short paper that tries to go against of this hype and provide a balanced view of the challenges that AI presents in language education. This post summarizes the key points from that paper, which is available in full here.\n","keywords":[],"articleBody":"Since ChatGPT burst onto the scene in November 2022 [18], educators worldwide have been grappling with a fundamental question: What are Large Language Models (LLMs) and How do we integrate Large Language Models (LLMs) into English language teaching?\nIn the recent Symposium on Using AI in Foreign Language Teaching hosted by FTU‚Äôs Faculty of ESP, I wrote a short paper that tries to go against of this hype and provide a balanced view of the challenges that AI presents in language education. This post summarizes the key points from that paper, which is available in full here.\nUnderstanding the AI Revolution in Education Before diving into the challenges, it‚Äôs crucial to understand what we‚Äôre dealing with. Large Language Models aren‚Äôt just sophisticated chatbots‚Äîthey‚Äôre advanced neural networks designed to predict the next word (token) in a sentence [2]. Tools like OpenAI‚Äôs GPT family [17], Google‚Äôs Gemini [19], and Meta‚Äôs Llama family [20] have evolved from simple text completion systems into ‚Äúinstructionally aligned‚Äù models that undergo fine-tuning with human-generated instructions to generate text that aligns with demonstrated human behaviors [3].\nThe appeal is obvious: imagine having an AI tutor available 24/7 that can explain complex grammar rules, provide vocabulary definitions, assist with translations, and even help with essay writing. For English language learners and teachers, this seems like a dream come true.\nThe Reality Check: Three Major Challenges 1. The Academic Integrity Crisis Here‚Äôs a sobering statistic: a typical 250-word essay assignment represents only about 340 tokens‚Äîa tiny fraction of what advanced AI models can process effortlessly. This means students can generate entire assignments with minimal personal effort, making traditional assessment methods increasingly obsolete.\nThe challenge isn‚Äôt just about cheating; it‚Äôs about authenticity. If language proficiency is supposed to reflect an individual‚Äôs ability to use the language for practical communication purposes [15], what happens when students rely on AI-generated text? We risk creating a generation of learners who can submit perfect essays but struggle with actual conversation. This scenario raises fundamental questions about the future role of writing tasks in language learning and assessment [12].\nThe solution? Educators need to pivot toward assessment methods that resist automation‚Äîthink oral examinations, real-time discussions, and collaborative projects that require genuine human interaction.\n2. The Over-Expectation Trap Students and educators alike are falling into what researchers call the ‚Äúover-expectation trap.‚Äù The Principle of Least Efforts [7] explains why students gravitate toward the most convenient search methods‚Äîand AI seems to fit perfectly. The convenience and apparent intelligence of AI tools lead many to treat them as infallible sources of knowledge. But here‚Äôs the catch: LLMs can ‚Äúhallucinate‚Äù‚Äîproducing convincing but incorrect information due to their probabilistic nature and potentially outdated training data [9], [4].\nTwo critical areas where this becomes problematic:\nVocabulary Learning: While AI can provide quick explanations of terms, users often skip verification, potentially learning incorrect definitions or usage patterns. Even advanced search engines like Google and Bing have tried to address this through retrieval-augmented generation systems [11], but questions about verifiability and accuracy remain [13].\nTranslation Tasks: LLMs show significant bias toward high-resource languages like English and German, performing poorly with less common languages due to systematic inequalities in training data and human evaluators [1], [23]. While they excel at translation-equivalent tasks like summarization, they struggle with translation-variant tasks such as back- and forward-translation, which are crucial for language learners [25].\n3. The Growing Digital Divide Perhaps the most troubling challenge is accessibility. High-performing AI models require substantial computing resources‚Äîwe‚Äôre talking multiple high-end GPUs for a single model. While cloud services offer solutions, they still require reliable internet connections and financial resources that many educational institutions simply don‚Äôt have.\nThis creates what researchers term the ‚ÄúAI divide‚Äù [10]‚Äîa new layer of inequality that exacerbates the existing digital divide in language and foreign language teaching [24]. Students from well-resourced institutions gain access to powerful learning tools while others are left behind. Quantitative evidence shows that students with formal educational credentials are significantly more likely to have future access to LLM technologies compared to those without such qualifications [6], potentially widening existing educational gaps.\nGrowing Evidence and Research The challenges outlined here are supported by emerging research across educational domains. Studies have shown both promise and concern‚Äîfor instance, recent research found that LLM-generated feedback from GPT-3.5-turbo improved essay revisions, task motivation, and positive emotions in secondary students compared to no feedback [16]. However, other studies highlight how generative AI is transforming computing education, forcing educators to reconsider fundamental approaches to teaching and assessment [14], [5].\nComprehensive reviews of LLM applications in education [21], [22] emphasize the need for careful consideration of benefits alongside risks, while policy experts at institutions like the Berkman Klein Center call for necessary safeguards to enable responsible use of these technologies [8].\nThe Path Forward: Strategic Integration, Not Blind Adoption Despite these challenges, the research doesn‚Äôt advocate for avoiding AI altogether. Instead, it calls for thoughtful, strategic integration that addresses these concerns:\nFor Educators: Develop new assessment methods that emphasize authentic language use Teach information literacy and critical evaluation skills Focus on AI as a supplement, not a replacement, for traditional learning methods For Institutions: Invest in digital infrastructure and training Develop policies around AI use that maintain academic integrity Consider partnerships with technology providers for equitable access For Policymakers: Address the AI divide through subsidized access programs Support infrastructure upgrades in underserved areas Develop guidelines for ethical AI use in education The Bottom Line The integration of AI into English language education is inevitable, but it‚Äôs not automatic. The research makes clear that we‚Äôre still in the early stages of understanding how to effectively and ethically use these powerful tools.\nThe key insight? We need to move beyond the hype and engage in serious, multidisciplinary collaboration between AI researchers, linguists, and education experts. Only through this collaborative approach can we harness the genuine benefits of AI while mitigating its risks.\nAs we stand at this crossroads, the choices we make today will shape the future of language education. The question isn‚Äôt whether AI will transform how we teach and learn languages‚Äîit‚Äôs whether we‚Äôll do it thoughtfully, equitably, and with genuine educational benefit in mind.\nThe promise is real, but so are the perils. Our responsibility as educators is to navigate this landscape with wisdom, ensuring that technology serves learning, not the other way around.\nReferences 1. Blasi, D., Anastasopoulos, A., \u0026 Neubig, G. (2021). Systematic inequalities in language technology performance across the world‚Äôs languages.\n2. Bowman, S. R. (2023). Eight things to know about large language models.\n3. Brown, T. B. (2020). Language models are few-shot learners.\n4. Cheng, J., Marone, M., Weller, O., Lawrie, D., Khashabi, D., \u0026 Durme, B. V. (2024). Dated data: Tracing knowledge cutoffs in large language models.\n5. Denny, P., Prather, J., Becker, B. A., Finnie-Ansley, J., Hellas, A., Leinonen, J., Luxton-Reilly, A., Reeves, B. N., Santos, E. A., \u0026 Sarsa, S. (2024). Computing education in the era of generative AI. Communication of the ACM, 67(2), 56‚Äì67.\n6. Eloundou, T., Manning, S., Mishkin, P., \u0026 Rock, D. (2023). GPTs are GPTs: An early look at the labor market impact potential of large language models.\n7. Fisher, K. E., Erdelez, S., \u0026 McKechnie, L. (2005). Theories of information behavior.\n8. Ha, Y. J. (2023). Exploring the impacts of generative AI on the future of teaching and learning.\n9. Huang, L., Yu, W., Ma, W., Zhong, W., Feng, Z., Wang, H., Chen, Q., Peng, W., Feng, X., Qin, B., \u0026 Liu, T. (2023). A survey on hallucination in large language models: Principles, taxonomy, challenges, and open questions.\n10. Kitsara, I. (2022). Artificial Intelligence and the Digital Divide: From an Innovation Perspective, pages 245‚Äì265. Springer International Publishing, Cham.\n11. Lewis, P., Perez, E., Piktus, A., Petroni, F., Karpukhin, V., Goyal, N., K√ºttler, H., Lewis, M., tau Yih, W., Rockt√§schel, T., Riedel, S., \u0026 Kiela, D. (2021). Retrieval-augmented generation for knowledge-intensive NLP tasks.\n12. Li, J. \u0026 Li, M. (2022). Assessing L2 writing in the digital age: Opportunities and challenges. Journal of Second Language Writing, 57:100913.\n13. Liu, N. F., Zhang, T., \u0026 Liang, P. (2023). Evaluating verifiability in generative search engines.\n14. MacNeil, S., Leinonen, J., Denny, P., Kiesler, N., Hellas, A., Prather, J., Becker, B. A., Wermelinger, M., \u0026 Reid, K. (2024). Discussing the changing landscape of generative AI in computing education. In Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 2, SIGCSE 2024, page 1916, New York, NY, USA. Association for Computing Machinery.\n15. Mayo, M. d. P. G. (2000). Focus on form in classroom second language acquisition. Studies in Second Language Acquisition, 22(1):123‚Äì124.\n16. Meyer, J., Jansen, T., Schiller, R., Liebenow, L. W., Steinbach, M., Horbach, A., \u0026 Fleckenstein, J. (2024). Using LLMs to bring evidence-based feedback into the classroom: AI-generated feedback increases secondary students‚Äô text revision, motivation, and positive emotions. Computers and Education: Artificial Intelligence, 6:100199.\n17. OpenAI (2023a). GPT-4 technical report.\n18. OpenAI (2023b). Introducing ChatGPT.\n19. Team, G. (2024). Gemini: A family of highly capable multimodal models.\n20. Touvron, H., Lavril, T., Izacard, G., Martinet, X., Lachaux, M.-A., Lacroix, T., Rozi√®re, B., Goyal, N., Hambro, E., Azhar, F., Rodriguez, A., Joulin, A., Grave, E., \u0026 Lample, G. (2023). Llama: Open and efficient foundation language models.\n21. Wang, S., Xu, T., Li, H., Zhang, C., Liang, J., Tang, J., Yu, P. S., \u0026 Wen, Q. (2024). Large language models for education: A survey and outlook.\n22. Wong, L.-H. \u0026 Looi, C.-K. (2024). Advancing the generative AI in education research agenda: Insights from the Asia-pacific region. Asia Pacific Journal of Education, 44(1), 1‚Äì7.\n23. Xu, S., Dong, W., Guo, Z., Wu, X., \u0026 Xiong, D. (2024). Exploring multilingual concepts of human value in large language models: Is value alignment consistent, transferable and controllable across languages?\n24. Yaman. (2015). Digital divide within the context of language and foreign language teaching. Procedia - Social and Behavioral Sciences, 176, 766‚Äì771.\n25. Zhang, X., Li, S., Hauer, B., Shi, N., \u0026 Kondrak, G. (2023). Don‚Äôt trust ChatGPT when your question is not in English: A study of multilingual abilities and types of LLMs. In Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing, pages 7915‚Äì7927, Singapore. Association for Computational Linguistics.\n","wordCount":"1697","inLanguage":"en","datePublished":"2024-06-20T17:01:23Z","dateModified":"2024-06-20T17:01:23Z","mainEntityOfPage":{"@type":"WebPage","@id":"https://dophganhh.github.io/posts/ai-challenges-in-education/"},"publisher":{"@type":"Organization","name":"Phuong Anh's Corner","logo":{"@type":"ImageObject","url":"https://dophganhh.github.io/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://dophganhh.github.io/ accesskey=h title="Phuong Anh's Corner (Alt + H)">Phuong Anh's Corner</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu></ul></nav></header><main class=main><article class=post-single><header class=post-header><h1 class="post-title entry-hint-parent">ü§ñ The Promise and Peril of AI in English Language Education: What Educators Need to Know</h1><div class=post-meta><span title='2024-06-20 17:01:23 +0000 UTC'>June 20, 2024</span></div></header><div class=post-content><p>Since ChatGPT burst onto the scene in November 2022 <a href=#ref18>[18]</a>, educators worldwide have been grappling with a fundamental question: What are Large Language Models (LLMs) and How do we integrate Large Language Models (LLMs) into English language teaching?</p><p>In the recent <a href=https://esp.ftu.edu.vn/hoi-thao-su-dung-tri-tue-nhan-tao-ai-trong-giang-day-ngoai-ngu-tai-cac-co-so-giao-duc-dai-hoc/>Symposium on Using AI in Foreign Language Teaching</a> hosted by <a href=https://esp.ftu.edu.vn/>FTU&rsquo;s Faculty of ESP</a>, I wrote a short paper that tries to go against of this hype and provide a balanced view of the challenges that AI presents in language education. This post summarizes the key points from that paper, which is available in full <a href=./publications/ky-yeu-hoi-thao-ftu-1.pdf>here</a>.</p><h2 id=understanding-the-ai-revolution-in-education>Understanding the AI Revolution in Education<a hidden class=anchor aria-hidden=true href=#understanding-the-ai-revolution-in-education>#</a></h2><p>Before diving into the challenges, it&rsquo;s crucial to understand what we&rsquo;re dealing with. Large Language Models aren&rsquo;t just sophisticated chatbots‚Äîthey&rsquo;re advanced neural networks designed to predict the next word (token) in a sentence <a href=#ref2>[2]</a>. Tools like OpenAI&rsquo;s GPT family <a href=#ref17>[17]</a>, Google&rsquo;s Gemini <a href=#ref19>[19]</a>, and Meta&rsquo;s Llama family <a href=#ref20>[20]</a> have evolved from simple text completion systems into &ldquo;instructionally aligned&rdquo; models that undergo fine-tuning with human-generated instructions to generate text that aligns with demonstrated human behaviors <a href=#ref3>[3]</a>.</p><p>The appeal is obvious: imagine having an AI tutor available 24/7 that can explain complex grammar rules, provide vocabulary definitions, assist with translations, and even help with essay writing. For English language learners and teachers, this seems like a dream come true.</p><h2 id=the-reality-check-three-major-challenges>The Reality Check: Three Major Challenges<a hidden class=anchor aria-hidden=true href=#the-reality-check-three-major-challenges>#</a></h2><h3 id=1-the-academic-integrity-crisis>1. The Academic Integrity Crisis<a hidden class=anchor aria-hidden=true href=#1-the-academic-integrity-crisis>#</a></h3><p>Here&rsquo;s a sobering statistic: a typical 250-word essay assignment represents only about 340 tokens‚Äîa tiny fraction of what advanced AI models can process effortlessly. This means students can generate entire assignments with minimal personal effort, making traditional assessment methods increasingly obsolete.</p><p>The challenge isn&rsquo;t just about cheating; it&rsquo;s about authenticity. If language proficiency is supposed to reflect an individual&rsquo;s ability to use the language for practical communication purposes <a href=#ref15>[15]</a>, what happens when students rely on AI-generated text? We risk creating a generation of learners who can submit perfect essays but struggle with actual conversation. This scenario raises fundamental questions about the future role of writing tasks in language learning and assessment <a href=#ref12>[12]</a>.</p><p><strong>The solution?</strong> Educators need to pivot toward assessment methods that resist automation‚Äîthink oral examinations, real-time discussions, and collaborative projects that require genuine human interaction.</p><h3 id=2-the-over-expectation-trap>2. The Over-Expectation Trap<a hidden class=anchor aria-hidden=true href=#2-the-over-expectation-trap>#</a></h3><p>Students and educators alike are falling into what researchers call the &ldquo;over-expectation trap.&rdquo; The Principle of Least Efforts <a href=#ref7>[7]</a> explains why students gravitate toward the most convenient search methods‚Äîand AI seems to fit perfectly. The convenience and apparent intelligence of AI tools lead many to treat them as infallible sources of knowledge. But here&rsquo;s the catch: LLMs can &ldquo;hallucinate&rdquo;‚Äîproducing convincing but incorrect information due to their probabilistic nature and potentially outdated training data <a href=#ref9>[9]</a>, <a href=#ref4>[4]</a>.</p><p><strong>Two critical areas where this becomes problematic:</strong></p><ul><li><p><strong>Vocabulary Learning</strong>: While AI can provide quick explanations of terms, users often skip verification, potentially learning incorrect definitions or usage patterns. Even advanced search engines like Google and Bing have tried to address this through retrieval-augmented generation systems <a href=#ref11>[11]</a>, but questions about verifiability and accuracy remain <a href=#ref13>[13]</a>.</p></li><li><p><strong>Translation Tasks</strong>: LLMs show significant bias toward high-resource languages like English and German, performing poorly with less common languages due to systematic inequalities in training data and human evaluators <a href=#ref1>[1]</a>, <a href=#ref23>[23]</a>. While they excel at translation-equivalent tasks like summarization, they struggle with translation-variant tasks such as back- and forward-translation, which are crucial for language learners <a href=#ref25>[25]</a>.</p></li></ul><h3 id=3-the-growing-digital-divide>3. The Growing Digital Divide<a hidden class=anchor aria-hidden=true href=#3-the-growing-digital-divide>#</a></h3><p>Perhaps the most troubling challenge is accessibility. High-performing AI models require substantial computing resources‚Äîwe&rsquo;re talking multiple high-end GPUs for a single model. While cloud services offer solutions, they still require reliable internet connections and financial resources that many educational institutions simply don&rsquo;t have.</p><p>This creates what researchers term the &ldquo;AI divide&rdquo; <a href=#ref10>[10]</a>‚Äîa new layer of inequality that exacerbates the existing digital divide in language and foreign language teaching <a href=#ref24>[24]</a>. Students from well-resourced institutions gain access to powerful learning tools while others are left behind. Quantitative evidence shows that students with formal educational credentials are significantly more likely to have future access to LLM technologies compared to those without such qualifications <a href=#ref6>[6]</a>, potentially widening existing educational gaps.</p><h2 id=growing-evidence-and-research>Growing Evidence and Research<a hidden class=anchor aria-hidden=true href=#growing-evidence-and-research>#</a></h2><p>The challenges outlined here are supported by emerging research across educational domains. Studies have shown both promise and concern‚Äîfor instance, recent research found that LLM-generated feedback from GPT-3.5-turbo improved essay revisions, task motivation, and positive emotions in secondary students compared to no feedback <a href=#ref16>[16]</a>. However, other studies highlight how generative AI is transforming computing education, forcing educators to reconsider fundamental approaches to teaching and assessment <a href=#ref14>[14]</a>, <a href=#ref5>[5]</a>.</p><p>Comprehensive reviews of LLM applications in education <a href=#ref21>[21]</a>, <a href=#ref22>[22]</a> emphasize the need for careful consideration of benefits alongside risks, while policy experts at institutions like the Berkman Klein Center call for necessary safeguards to enable responsible use of these technologies <a href=#ref8>[8]</a>.</p><h2 id=the-path-forward-strategic-integration-not-blind-adoption>The Path Forward: Strategic Integration, Not Blind Adoption<a hidden class=anchor aria-hidden=true href=#the-path-forward-strategic-integration-not-blind-adoption>#</a></h2><p>Despite these challenges, the research doesn&rsquo;t advocate for avoiding AI altogether. Instead, it calls for thoughtful, strategic integration that addresses these concerns:</p><h3 id=for-educators>For Educators:<a hidden class=anchor aria-hidden=true href=#for-educators>#</a></h3><ul><li>Develop new assessment methods that emphasize authentic language use</li><li>Teach information literacy and critical evaluation skills</li><li>Focus on AI as a supplement, not a replacement, for traditional learning methods</li></ul><h3 id=for-institutions>For Institutions:<a hidden class=anchor aria-hidden=true href=#for-institutions>#</a></h3><ul><li>Invest in digital infrastructure and training</li><li>Develop policies around AI use that maintain academic integrity</li><li>Consider partnerships with technology providers for equitable access</li></ul><h3 id=for-policymakers>For Policymakers:<a hidden class=anchor aria-hidden=true href=#for-policymakers>#</a></h3><ul><li>Address the AI divide through subsidized access programs</li><li>Support infrastructure upgrades in underserved areas</li><li>Develop guidelines for ethical AI use in education</li></ul><h2 id=the-bottom-line>The Bottom Line<a hidden class=anchor aria-hidden=true href=#the-bottom-line>#</a></h2><p>The integration of AI into English language education is inevitable, but it&rsquo;s not automatic. The research makes clear that we&rsquo;re still in the early stages of understanding how to effectively and ethically use these powerful tools.</p><p>The key insight? We need to move beyond the hype and engage in serious, multidisciplinary collaboration between AI researchers, linguists, and education experts. Only through this collaborative approach can we harness the genuine benefits of AI while mitigating its risks.</p><p>As we stand at this crossroads, the choices we make today will shape the future of language education. The question isn&rsquo;t whether AI will transform how we teach and learn languages‚Äîit&rsquo;s whether we&rsquo;ll do it thoughtfully, equitably, and with genuine educational benefit in mind.</p><p>The promise is real, but so are the perils. Our responsibility as educators is to navigate this landscape with wisdom, ensuring that technology serves learning, not the other way around.</p><hr><h2 id=references>References<a hidden class=anchor aria-hidden=true href=#references>#</a></h2><p>1. Blasi, D., Anastasopoulos, A., & Neubig, G. (2021). Systematic inequalities in language technology performance across the world&rsquo;s languages.</p><p>2. Bowman, S. R. (2023). Eight things to know about large language models.</p><p>3. Brown, T. B. (2020). Language models are few-shot learners.</p><p>4. Cheng, J., Marone, M., Weller, O., Lawrie, D., Khashabi, D., & Durme, B. V. (2024). Dated data: Tracing knowledge cutoffs in large language models.</p><p>5. Denny, P., Prather, J., Becker, B. A., Finnie-Ansley, J., Hellas, A., Leinonen, J., Luxton-Reilly, A., Reeves, B. N., Santos, E. A., & Sarsa, S. (2024). Computing education in the era of generative AI. Communication of the ACM, 67(2), 56‚Äì67.</p><p>6. Eloundou, T., Manning, S., Mishkin, P., & Rock, D. (2023). GPTs are GPTs: An early look at the labor market impact potential of large language models.</p><p>7. Fisher, K. E., Erdelez, S., & McKechnie, L. (2005). Theories of information behavior.</p><p>8. Ha, Y. J. (2023). Exploring the impacts of generative AI on the future of teaching and learning.</p><p>9. Huang, L., Yu, W., Ma, W., Zhong, W., Feng, Z., Wang, H., Chen, Q., Peng, W., Feng, X., Qin, B., & Liu, T. (2023). A survey on hallucination in large language models: Principles, taxonomy, challenges, and open questions.</p><p>10. Kitsara, I. (2022). Artificial Intelligence and the Digital Divide: From an Innovation Perspective, pages 245‚Äì265. Springer International Publishing, Cham.</p><p>11. Lewis, P., Perez, E., Piktus, A., Petroni, F., Karpukhin, V., Goyal, N., K√ºttler, H., Lewis, M., tau Yih, W., Rockt√§schel, T., Riedel, S., & Kiela, D. (2021). Retrieval-augmented generation for knowledge-intensive NLP tasks.</p><p>12. Li, J. & Li, M. (2022). Assessing L2 writing in the digital age: Opportunities and challenges. Journal of Second Language Writing, 57:100913.</p><p>13. Liu, N. F., Zhang, T., & Liang, P. (2023). Evaluating verifiability in generative search engines.</p><p>14. MacNeil, S., Leinonen, J., Denny, P., Kiesler, N., Hellas, A., Prather, J., Becker, B. A., Wermelinger, M., & Reid, K. (2024). Discussing the changing landscape of generative AI in computing education. In Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 2, SIGCSE 2024, page 1916, New York, NY, USA. Association for Computing Machinery.</p><p>15. Mayo, M. d. P. G. (2000). Focus on form in classroom second language acquisition. Studies in Second Language Acquisition, 22(1):123‚Äì124.</p><p>16. Meyer, J., Jansen, T., Schiller, R., Liebenow, L. W., Steinbach, M., Horbach, A., & Fleckenstein, J. (2024). Using LLMs to bring evidence-based feedback into the classroom: AI-generated feedback increases secondary students&rsquo; text revision, motivation, and positive emotions. Computers and Education: Artificial Intelligence, 6:100199.</p><p>17. OpenAI (2023a). GPT-4 technical report.</p><p>18. OpenAI (2023b). Introducing ChatGPT.</p><p>19. Team, G. (2024). Gemini: A family of highly capable multimodal models.</p><p>20. Touvron, H., Lavril, T., Izacard, G., Martinet, X., Lachaux, M.-A., Lacroix, T., Rozi√®re, B., Goyal, N., Hambro, E., Azhar, F., Rodriguez, A., Joulin, A., Grave, E., & Lample, G. (2023). Llama: Open and efficient foundation language models.</p><p>21. Wang, S., Xu, T., Li, H., Zhang, C., Liang, J., Tang, J., Yu, P. S., & Wen, Q. (2024). Large language models for education: A survey and outlook.</p><p>22. Wong, L.-H. & Looi, C.-K. (2024). Advancing the generative AI in education research agenda: Insights from the Asia-pacific region. Asia Pacific Journal of Education, 44(1), 1‚Äì7.</p><p>23. Xu, S., Dong, W., Guo, Z., Wu, X., & Xiong, D. (2024). Exploring multilingual concepts of human value in large language models: Is value alignment consistent, transferable and controllable across languages?</p><p>24. Yaman. (2015). Digital divide within the context of language and foreign language teaching. Procedia - Social and Behavioral Sciences, 176, 766‚Äì771.</p><p>25. Zhang, X., Li, S., Hauer, B., Shi, N., & Kondrak, G. (2023). Don&rsquo;t trust ChatGPT when your question is not in English: A study of multilingual abilities and types of LLMs. In Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing, pages 7915‚Äì7927, Singapore. Association for Computational Linguistics.</p></div><footer class=post-footer><ul class=post-tags></ul></footer></article></main><footer class=footer><span>&copy; 2025 <a href=https://dophganhh.github.io/>Phuong Anh's Corner</a></span> ¬∑
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>